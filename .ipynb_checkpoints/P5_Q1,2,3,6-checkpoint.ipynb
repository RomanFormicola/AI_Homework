{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1)** Group Eta: Roman Formicola"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) a)**\n",
    "\n",
    "$P(class=1) = 1/4\\\\\n",
    "P(class=2) = 1/2\\\\\n",
    "P(class=3) = 1/4\\\\\n",
    "|V| = 14\\\\\n",
    "\\hat{P}(t|c) = (N_{ct} + 1)/(N_{c} + 2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**i**)  $P(X_{peony}=T | class=2) = 3/4$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ii)** $P(X_{crocus}=T|class=2) = 1/2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**iii)** $P(X_{peony}=T|class=1) = 2/3$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)**\n",
    "\n",
    "$P(t | c) = (count(t, c) + 1)/(count(t) + |v|)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**i**) $P(X = peony | class=2) = (4+1) / (14+14) = 5/28$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ii)** $P(X=crocus | class=2) = (1+1)/(14+14) = 2/28 = 1/14$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**iii)** $P(X=peony|class=1) = (1+1)/(8+14) = 2/22 = 1/11$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)**\n",
    "\n",
    "$P(d | class = 1)= P(1)*P(X_{daffodil}=T|class=1)*P(X_{crocus}=T|class=1)*P(X_{daisy}=T|class=1)*P(X_{tulip}=T|class=1)\\\\\n",
    "*P(X_{clematis}=T|class=1)*P(X_{peony}=T|class=1) = (1/4)*(1/3)*(1/3)*(1/3)*(2/3)*(2/3)*(2/3) \\approx 0.002743$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(d | class = 2)= P(2)*P(X_{daffodil}=T|class=2)*P(X_{crocus}=T|class=2)*P(X_{daisy}=T|class=2)*P(X_{tulip}=T|class=2)\\\\\n",
    "*P(X_{clematis}=T|class=2)*P(X_{peony}=T|class=2) = (1/2)*(1/2)*(1/2)*(1/4)*(1/4)*(3/4)*(3/4) \\approx 0.0043945$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(d | class = 3)= P(3)*P(X_{daffodil}=T|class=3)*P(X_{crocus}=T|class=3)*P(X_{daisy}=T|class=3)*P(X_{tulip}=T|class=3)\\\\\n",
    "*P(X_{clematis}=T|class=3)*P(X_{peony}=T|class=3) = (1/4)*(1/3)*(1/3)*(2/3)*(2/3)*(1/3)*(1/3)\\approx 0.00137174$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicted class for document: daffodil crocus daisy tulip clematis peony = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(d|class=1)=P(X=daffodil|class=1)*P(X=crocus|class=1)*P(X=daisy|class=1)*P(X=tulip|class=1)*P(X=clemantis|class=1)*P(X=peony|class=1)=(1/4)*(1/22)*(1/22)*(1/22)*(1/11)*(1/11)*(1/11) \\approx 1.76398*10^{-8}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(d|class=2)=P(X=daffodil|class=2)*P(X=crocus|class=2)*P(X=daisy|class=2)*P(X=tulip|class=2)*P(X=clemantis|class=2)*P(X=peony|class=2)=(1/2)*(1/14)*(1/14)*(1/28)*(1/28)*(5/28)*(5/28) \\approx 1.03758*10^{-7}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(d|class=3)=P(X=daffodil|class=3)*P(X=crocus|class=3)*P(X=daisy|class=3)*P(X=tulip|class=3)*P(X=clemantis|class=3)*P(X=peony|class=3)=(1/4)*(1/21)*(1/21)*(2/21)*(3/21)*(1/21)*(1/21) \\approx 1.74894*10^{-8}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicted class for document: daffodil crocus daisy tulip clematis peony = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_565db600_9f0a_11eb_949b_7085c2f4e290\" ><caption>Term Document Matrix</caption><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >cat</th>        <th class=\"col_heading level0 col1\" >bat</th>        <th class=\"col_heading level0 col2\" >rat</th>        <th class=\"col_heading level0 col3\" >fat</th>        <th class=\"col_heading level0 col4\" >mat</th>        <th class=\"col_heading level0 col5\" >pat</th>        <th class=\"col_heading level0 col6\" >sat</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_565db600_9f0a_11eb_949b_7085c2f4e290level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_565db600_9f0a_11eb_949b_7085c2f4e290row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "                        <td id=\"T_565db600_9f0a_11eb_949b_7085c2f4e290row0_col1\" class=\"data row0 col1\" >1</td>\n",
       "                        <td id=\"T_565db600_9f0a_11eb_949b_7085c2f4e290row0_col2\" class=\"data row0 col2\" >1</td>\n",
       "                        <td id=\"T_565db600_9f0a_11eb_949b_7085c2f4e290row0_col3\" class=\"data row0 col3\" >1</td>\n",
       "                        <td id=\"T_565db600_9f0a_11eb_949b_7085c2f4e290row0_col4\" class=\"data row0 col4\" >0</td>\n",
       "                        <td id=\"T_565db600_9f0a_11eb_949b_7085c2f4e290row0_col5\" class=\"data row0 col5\" >0</td>\n",
       "                        <td id=\"T_565db600_9f0a_11eb_949b_7085c2f4e290row0_col6\" class=\"data row0 col6\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_565db600_9f0a_11eb_949b_7085c2f4e290level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_565db600_9f0a_11eb_949b_7085c2f4e290row1_col0\" class=\"data row1 col0\" >0</td>\n",
       "                        <td id=\"T_565db600_9f0a_11eb_949b_7085c2f4e290row1_col1\" class=\"data row1 col1\" >1</td>\n",
       "                        <td id=\"T_565db600_9f0a_11eb_949b_7085c2f4e290row1_col2\" class=\"data row1 col2\" >1</td>\n",
       "                        <td id=\"T_565db600_9f0a_11eb_949b_7085c2f4e290row1_col3\" class=\"data row1 col3\" >0</td>\n",
       "                        <td id=\"T_565db600_9f0a_11eb_949b_7085c2f4e290row1_col4\" class=\"data row1 col4\" >1</td>\n",
       "                        <td id=\"T_565db600_9f0a_11eb_949b_7085c2f4e290row1_col5\" class=\"data row1 col5\" >1</td>\n",
       "                        <td id=\"T_565db600_9f0a_11eb_949b_7085c2f4e290row1_col6\" class=\"data row1 col6\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_565db600_9f0a_11eb_949b_7085c2f4e290level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_565db600_9f0a_11eb_949b_7085c2f4e290row2_col0\" class=\"data row2 col0\" >1</td>\n",
       "                        <td id=\"T_565db600_9f0a_11eb_949b_7085c2f4e290row2_col1\" class=\"data row2 col1\" >0</td>\n",
       "                        <td id=\"T_565db600_9f0a_11eb_949b_7085c2f4e290row2_col2\" class=\"data row2 col2\" >1</td>\n",
       "                        <td id=\"T_565db600_9f0a_11eb_949b_7085c2f4e290row2_col3\" class=\"data row2 col3\" >1</td>\n",
       "                        <td id=\"T_565db600_9f0a_11eb_949b_7085c2f4e290row2_col4\" class=\"data row2 col4\" >1</td>\n",
       "                        <td id=\"T_565db600_9f0a_11eb_949b_7085c2f4e290row2_col5\" class=\"data row2 col5\" >1</td>\n",
       "                        <td id=\"T_565db600_9f0a_11eb_949b_7085c2f4e290row2_col6\" class=\"data row2 col6\" >1</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1f0a5dc4520>"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "term_doc_matrix = [[1, 1, 1, 1, 0, 0, 0], [0, 1, 1, 0, 1, 1, 0], [1, 0, 1, 1, 1, 1, 1]]\n",
    "df = pd.DataFrame(term_doc_matrix, columns=[\"cat\", \"bat\", \"rat\", \"fat\", \"mat\", \"pat\", \"sat\"])\n",
    "df.style.set_caption(\"Term Document Matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Note: I used $Log_{10}(1+tf_{t,d})*Log_{10}(N/df_{t})$  for TF-IDF weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_5660898f_9f0a_11eb_a9a9_7085c2f4e290\" ><caption>TF-IDF Matrix</caption><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >cat</th>        <th class=\"col_heading level0 col1\" >bat</th>        <th class=\"col_heading level0 col2\" >rat</th>        <th class=\"col_heading level0 col3\" >fat</th>        <th class=\"col_heading level0 col4\" >mat</th>        <th class=\"col_heading level0 col5\" >pat</th>        <th class=\"col_heading level0 col6\" >sat</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_5660898f_9f0a_11eb_a9a9_7085c2f4e290level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_5660898f_9f0a_11eb_a9a9_7085c2f4e290row0_col0\" class=\"data row0 col0\" >0.106000</td>\n",
       "                        <td id=\"T_5660898f_9f0a_11eb_a9a9_7085c2f4e290row0_col1\" class=\"data row0 col1\" >0.053000</td>\n",
       "                        <td id=\"T_5660898f_9f0a_11eb_a9a9_7085c2f4e290row0_col2\" class=\"data row0 col2\" >0</td>\n",
       "                        <td id=\"T_5660898f_9f0a_11eb_a9a9_7085c2f4e290row0_col3\" class=\"data row0 col3\" >0.053000</td>\n",
       "                        <td id=\"T_5660898f_9f0a_11eb_a9a9_7085c2f4e290row0_col4\" class=\"data row0 col4\" >0.000000</td>\n",
       "                        <td id=\"T_5660898f_9f0a_11eb_a9a9_7085c2f4e290row0_col5\" class=\"data row0 col5\" >0.000000</td>\n",
       "                        <td id=\"T_5660898f_9f0a_11eb_a9a9_7085c2f4e290row0_col6\" class=\"data row0 col6\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5660898f_9f0a_11eb_a9a9_7085c2f4e290level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_5660898f_9f0a_11eb_a9a9_7085c2f4e290row1_col0\" class=\"data row1 col0\" >0.000000</td>\n",
       "                        <td id=\"T_5660898f_9f0a_11eb_a9a9_7085c2f4e290row1_col1\" class=\"data row1 col1\" >0.106000</td>\n",
       "                        <td id=\"T_5660898f_9f0a_11eb_a9a9_7085c2f4e290row1_col2\" class=\"data row1 col2\" >0</td>\n",
       "                        <td id=\"T_5660898f_9f0a_11eb_a9a9_7085c2f4e290row1_col3\" class=\"data row1 col3\" >0.000000</td>\n",
       "                        <td id=\"T_5660898f_9f0a_11eb_a9a9_7085c2f4e290row1_col4\" class=\"data row1 col4\" >0.053000</td>\n",
       "                        <td id=\"T_5660898f_9f0a_11eb_a9a9_7085c2f4e290row1_col5\" class=\"data row1 col5\" >0.053000</td>\n",
       "                        <td id=\"T_5660898f_9f0a_11eb_a9a9_7085c2f4e290row1_col6\" class=\"data row1 col6\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5660898f_9f0a_11eb_a9a9_7085c2f4e290level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_5660898f_9f0a_11eb_a9a9_7085c2f4e290row2_col0\" class=\"data row2 col0\" >0.053000</td>\n",
       "                        <td id=\"T_5660898f_9f0a_11eb_a9a9_7085c2f4e290row2_col1\" class=\"data row2 col1\" >0.000000</td>\n",
       "                        <td id=\"T_5660898f_9f0a_11eb_a9a9_7085c2f4e290row2_col2\" class=\"data row2 col2\" >0</td>\n",
       "                        <td id=\"T_5660898f_9f0a_11eb_a9a9_7085c2f4e290row2_col3\" class=\"data row2 col3\" >0.053000</td>\n",
       "                        <td id=\"T_5660898f_9f0a_11eb_a9a9_7085c2f4e290row2_col4\" class=\"data row2 col4\" >0.053000</td>\n",
       "                        <td id=\"T_5660898f_9f0a_11eb_a9a9_7085c2f4e290row2_col5\" class=\"data row2 col5\" >0.053000</td>\n",
       "                        <td id=\"T_5660898f_9f0a_11eb_a9a9_7085c2f4e290row2_col6\" class=\"data row2 col6\" >0.143600</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1f0a5f72ca0>"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TF_IDF = [[0.106, 0.053, 0, 0.053, 0, 0, 0], [0, 0.106, 0, 0, 0.053, 0.053, 0], \n",
    "          [0.053, 0, 0, 0.053, 0.053, 0.053, 0.1436]]\n",
    "df = df = pd.DataFrame(TF_IDF, columns=[\"cat\", \"bat\", \"rat\", \"fat\", \"mat\", \"pat\", \"sat\"])\n",
    "df.style.set_caption(\"TF-IDF Matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** The term-document pair witht the highest TF-IDF weight is (Doc 3, \"sat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B\n",
    "### Question 4\n",
    "### Question 5\n",
    "### Question 6\n",
    "#### Part a\n",
    "    Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "%matplotlib inline\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "# Read Speeches\n",
    "#listFiles = [f for f in listdir(\"sotu/files/\") if isfile(join(\"sotu/files/\", f))]\n",
    "listFiles = [\"a\" + str(i) + \".txt\" for i in range(1, 232)]\n",
    "\n",
    "sotus = []\n",
    "for fi in listFiles:\n",
    "    file_path = \"sotu/files/%s\" % (fi)\n",
    "    with open(file_path) as f:\n",
    "        sotus.append(f.read().splitlines())\n",
    "        f.close()\n",
    "\n",
    "# Read Party Data\n",
    "with open(\"sotu/party.txt\") as f:\n",
    "    speechData= f.read().splitlines()\n",
    "    f.close()\n",
    "    \n",
    "for i in range(len(speechData)):\n",
    "    party[i] = speechData[i][:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part b\n",
    "    Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Stop Words list, stopwds\n",
    "with open(\"sotu/stopwords.txt\") as f:\n",
    "    stopwds = f.read().splitlines()\n",
    "    f.close()\n",
    "    \n",
    "sotusNoStop = []\n",
    "# Remove Stop Words from sotus\n",
    "for speech in range(len(sotus)):\n",
    "    hold = []\n",
    "    for word in sotus[speech]:\n",
    "        \n",
    "        if not word in stopwds:\n",
    "            hold.append(word)\n",
    "        \n",
    "    sotusNoStop.append(hold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part c\n",
    "##### i. Term-Document Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>government</th>\n",
       "      <th>states</th>\n",
       "      <th>congress</th>\n",
       "      <th>united</th>\n",
       "      <th>people</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>d, jackson, 1829</th>\n",
       "      <td>58</td>\n",
       "      <td>46</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d, jackson, 1830</th>\n",
       "      <td>68</td>\n",
       "      <td>78</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d, jackson, 1831</th>\n",
       "      <td>26</td>\n",
       "      <td>34</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d, jackson, 1832</th>\n",
       "      <td>36</td>\n",
       "      <td>34</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d, jackson, 1833</th>\n",
       "      <td>43</td>\n",
       "      <td>53</td>\n",
       "      <td>24</td>\n",
       "      <td>44</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d, jackson, 1834</th>\n",
       "      <td>74</td>\n",
       "      <td>65</td>\n",
       "      <td>52</td>\n",
       "      <td>54</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d, jackson, 1835</th>\n",
       "      <td>69</td>\n",
       "      <td>49</td>\n",
       "      <td>50</td>\n",
       "      <td>45</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d, jackson, 1836</th>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d, van buren, 1837</th>\n",
       "      <td>71</td>\n",
       "      <td>60</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d, van buren, 1838</th>\n",
       "      <td>64</td>\n",
       "      <td>74</td>\n",
       "      <td>31</td>\n",
       "      <td>60</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    government  states  congress  united  people\n",
       "d, jackson, 1829            58      46        20      23      23\n",
       "d, jackson, 1830            68      78        27      32      37\n",
       "d, jackson, 1831            26      34        19      12      10\n",
       "d, jackson, 1832            36      34        14      12      20\n",
       "d, jackson, 1833            43      53        24      44       8\n",
       "d, jackson, 1834            74      65        52      54      21\n",
       "d, jackson, 1835            69      49        50      45      22\n",
       "d, jackson, 1836            57      57        29      29      30\n",
       "d, van buren, 1837          71      60        29      30      14\n",
       "d, van buren, 1838          64      74        31      60      17"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which speeches are in the training set\n",
    "trainIndex = []\n",
    "for i in range(len(speechData)):\n",
    "    if not speechData[i][-4:] in [\"1962\", \"1995\", \"2006\", \"2014\", \"2017\"]:\n",
    "        if party[i] == \"d\" or party[i] == \"r\":\n",
    "            trainIndex.append(i)\n",
    "    \n",
    "# Which speeches are to be tested\n",
    "testIndex = []    \n",
    "for i in range(len(speechData)):\n",
    "    if speechData[i][-4:] in [\"1962\", \"1995\", \"2006\", \"2014\", \"2017\"]:\n",
    "        testIndex.append(i)\n",
    "        \n",
    "trainingComplete = []\n",
    "for i in trainIndex:\n",
    "    trainingComplete.append(sotusNoStop[i])\n",
    "for i in testIndex:\n",
    "    trainingComplete.append(sotusNoStop[i])\n",
    "    \n",
    "for i in range(len(trainingComplete)):\n",
    "    hold = \"\"\n",
    "    for word in trainingComplete[i]:\n",
    "        hold += word\n",
    "        hold += \" \"\n",
    "    trainingComplete[i] = hold\n",
    "    \n",
    "for i in range(len(testComplete)):\n",
    "    hold = \"\"\n",
    "    for word in testComplete[i]:\n",
    "        hold += word\n",
    "        hold += \" \"\n",
    "    testComplete[i] = hold\n",
    "        \n",
    "# Create Count Vectors\n",
    "vect = CountVectorizer(input='content', max_features=3000)\n",
    "vects = vect.fit_transform(trainingComplete)\n",
    "\n",
    "df = pd.DataFrame(vects.toarray(), \n",
    "                      index=[speechData[i] for i in trainIndex] + [speechData[i] for i in testIndex], \n",
    "                      columns=vect.get_feature_names())\n",
    "\n",
    "df = df.T\n",
    "df['Totals'] = df.sum(axis=1)\n",
    "\n",
    "df = df.T\n",
    "\n",
    "df = df.sort_values(by='Totals', axis = 1, ascending=False)\n",
    "df.iloc[:10,:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ii. Bernoulli Model Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P(C=Dems|X)</th>\n",
       "      <th>P(C=Reb|X)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>d, kennedy, 1962</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d, clinton, 1995</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r, bush, 2006</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d, obama, 2014</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r, trump, 2017</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  P(C=Dems|X)  P(C=Reb|X)\n",
       "d, kennedy, 1962          1.0         0.0\n",
       "d, clinton, 1995          1.0         0.0\n",
       "r, bush, 2006             1.0         0.0\n",
       "d, obama, 2014            1.0         0.0\n",
       "r, trump, 2017            1.0         0.0"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "partyResults = []\n",
    "for i in trainIndex:\n",
    "    partyResults.append(party[i])\n",
    "    \n",
    "clf = BernoulliNB()\n",
    "clf.fit(df.iloc[:178], partyResults)\n",
    "\n",
    "prediction = clf.predict_proba(df.iloc[178:183])\n",
    "\n",
    "predictionDF = pd.DataFrame(prediction, columns=[\"P(C=Dems|X)\", \"P(C=Reb|X)\"],\n",
    "                               index = [speechData[i] for i in testIndex])\n",
    "\n",
    "predictionDF.round(decimals = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### iii. Multinomial Model Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P(C=Dems|X)</th>\n",
       "      <th>P(C=Reb|X)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>d, kennedy, 1962</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d, clinton, 1995</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r, bush, 2006</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d, obama, 2014</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r, trump, 2017</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  P(C=Dems|X)  P(C=Reb|X)\n",
       "d, kennedy, 1962          1.0         0.0\n",
       "d, clinton, 1995          1.0         0.0\n",
       "r, bush, 2006             1.0         0.0\n",
       "d, obama, 2014            1.0         0.0\n",
       "r, trump, 2017            1.0         0.0"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "partyResults = []\n",
    "for i in trainIndex:\n",
    "    partyResults.append(party[i])\n",
    "    \n",
    "clf = MultinomialNB()\n",
    "clf.fit(df.iloc[:178], partyResults)\n",
    "\n",
    "prediction = clf.predict_proba(df.iloc[178:183])\n",
    "\n",
    "predictionDF = pd.DataFrame(prediction, columns=[\"P(C=Dems|X)\", \"P(C=Reb|X)\"],\n",
    "                               index = [speechData[i] for i in testIndex])\n",
    "\n",
    "predictionDF.round(decimals = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
