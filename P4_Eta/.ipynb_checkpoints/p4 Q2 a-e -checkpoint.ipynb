{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 4\n",
    "## Group: P2eta\n",
    "## Members: Paul Rayment, Andrew Peters Roman Formicola"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split: 1\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'f1_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-06eb89fbc761>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0mperformance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myhat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m     \u001b[0mperformance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myhat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m     \u001b[0mperformance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myhat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'f1_score' is not defined"
     ]
    }
   ],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn import cluster\n",
    "from sklearn import neighbors\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score \n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import pandas as pd\n",
    "\n",
    "# Load Data\n",
    "data = pd.read_csv(\"hit-movies.csv\")\n",
    "\n",
    "# Trim Data\n",
    "data = pd.DataFrame(data)\n",
    "data.pop(\"original_title\")\n",
    "data.pop(\"imdb_id\")\n",
    "\n",
    "# Seperate \"Hit\" as target\n",
    "target = data.pop(\"Hit\")\n",
    "\n",
    "# Scale Data\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(data)\n",
    "data = pd.DataFrame(scaler.transform(data))\n",
    "\n",
    "# Record Mean Accuracy, F1 Measure, and AUC\n",
    "rows = [\"KNN3\", \"KNN9\", \"KNN15\", \"DT1\", \"DT2\", \"NB\", \"best SVM\", \"best RF\", \"best AdaBoost\"]\n",
    "cols = [\"Accuracy\", \"F1-Measure\", \"AUC\"]\n",
    "performance = [[0,0,0],[0,0,0],[0,0,0],\n",
    "              [0,0,0],[0,0,0],[0,0,0],\n",
    "              [0,0,0],[0,0,0],[0,0,0]]\n",
    "split = 1\n",
    "# Set up Cross Validation Splits\n",
    "cv_outer = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "for train_ix, test_ix in cv_outer.split(data):\n",
    "    # Split the Data\n",
    "    data_train, data_test = data.iloc[train_ix], data.iloc[test_ix] \n",
    "    target_train, target_test = target[train_ix], target[test_ix]\n",
    "\n",
    "    # Q2c - kNN\n",
    "    # k = 3\n",
    "    km = neighbors.KNeighborsClassifier(n_neighbors = 3)\n",
    "    pred_test = km.fit(data_train, target_train).predict(data_test)\n",
    "    performance[0][0] += metrics.accuracy_score(target_test, pred_test)\n",
    "    performance[0][1] += metrics.f1_score(target_test, pred_test)\n",
    "    performance[0][2] += metrics.roc_auc_score(target_test, pred_test)\n",
    "    \n",
    "    # k = 9\n",
    "    km = neighbors.KNeighborsClassifier(n_neighbors = 9)\n",
    "    pred_test = km.fit(data_train, target_train).predict(data_test)\n",
    "    performance[1][0] += metrics.accuracy_score(target_test, pred_test)\n",
    "    performance[1][1] += metrics.f1_score(target_test, pred_test)\n",
    "    performance[1][2] += metrics.roc_auc_score(target_test, pred_test)\n",
    "    \n",
    "    # k = 15\n",
    "    km = neighbors.KNeighborsClassifier(n_neighbors = 15)\n",
    "    pred_test = km.fit(data_train, target_train).predict(data_test)\n",
    "    performance[2][0] += metrics.accuracy_score(target_test, pred_test)\n",
    "    performance[2][1] += metrics.f1_score(target_test, pred_test)\n",
    "    performance[2][2] += metrics.roc_auc_score(target_test, pred_test)\n",
    "    \n",
    "    # Q2d - Decision Tree (Two Depths)\n",
    "    # DT1 - depth 8\n",
    "    dt = tree.DecisionTreeClassifier(max_depth=8, class_weight=\"balanced\")\n",
    "    pred_test = dt.fit(data_train, target_train).predict(data_test)\n",
    "    performance[3][0] += metrics.accuracy_score(target_test, pred_test)\n",
    "    performance[3][1] += metrics.f1_score(target_test, pred_test)\n",
    "    performance[3][2] += metrics.roc_auc_score(target_test, pred_test)\n",
    "    \n",
    "    # DT2 - depth 12\n",
    "    out = tree.DecisionTreeClassifier(max_depth=12, class_weight=\"balanced\")\n",
    "    pred_test = dt.fit(data_train, target_train).predict(data_test)\n",
    "    performance[4][0] += metrics.accuracy_score(target_test, pred_test)\n",
    "    performance[4][1] += metrics.f1_score(target_test, pred_test)\n",
    "    performance[4][2] += metrics.roc_auc_score(target_test, pred_test)\n",
    "    \n",
    "    # Q2e - Naive bayes\n",
    "    nb = naive_bayes.GaussianNB()\n",
    "    pred_test = nb.fit(data_train, target_train).predict(data_test)\n",
    "    performance[5][0] += metrics.accuracy_score(target_test, pred_test)\n",
    "    performance[5][1] += metrics.f1_score(target_test, pred_test)\n",
    "    performance[5][2] += metrics.roc_auc_score(target_test, pred_test)\n",
    "    \n",
    "    # set up the cross-validation procedure\n",
    "    cv_inner = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    print(\"Split:\", split)\n",
    "    # Q2f(i) - SVM\n",
    "\n",
    "    params = [{'kernel':['rbf'], 'C':[0.01, 0.1, 1]},\n",
    "              {'kernel':['poly'], 'degree':[2], 'C':[0.01, 0.1, 1]}, \n",
    "              {'kernel':['poly'], 'degree':[3], 'C':[0.01, 0.1, 1]}, \n",
    "              {'kernel':['poly'], 'degree':[4], 'C':[0.01, 0.1, 1]}]\n",
    "    svc = SVC()\n",
    "    svc_search = GridSearchCV(svc, params, scoring='roc_auc', cv=cv_inner, refit=True)\n",
    "    result = svc_search.fit(data_train, target_train)\n",
    "    \n",
    "    best_model = result.best_estimator_\n",
    "    yhat = best_model.predict(data_test)\n",
    "    performance[6][0] += metrics.accuracy_score(target_test, yhat)\n",
    "    performance[6][1] += metrics.f1_score(target_test, yhat)\n",
    "    performance[6][2] += metrics.roc_auc_score(target_test, yhat)\n",
    "    \n",
    "    print(\"SVC Best Param:\", result.best_params_)\n",
    "    \n",
    "    # Q2f(ii) - Random Forests\n",
    "    forest = RandomForestClassifier()\n",
    "    space = dict()\n",
    "    space['n_estimators'] = [25, 50, 100]\n",
    "    space['max_features'] = [6, 10, 14]\n",
    "    \n",
    "    forest_search = GridSearchCV(forest, space, scoring='roc_auc', cv=cv_inner, refit=True)\n",
    "    result = forest_search.fit(data_train, target_train)\n",
    "    \n",
    "    best_model = result.best_estimator_\n",
    "    yhat = best_model.predict(data_test)\n",
    "    performance[7][0] += metrics.accuracy_score(target_test, yhat)\n",
    "    performance[7][1] += metrics.f1_score(target_test, yhat)\n",
    "    performance[7][2] += metrics.roc_auc_score(target_test, yhat)\n",
    "    \n",
    "    print(\"Random Forest Best Param:\", result.best_params_)\n",
    "    \n",
    "    # Q2f(iii) - AdaBoost\n",
    "    \n",
    "    ada = AdaBoostClassifier()\n",
    "    space = dict()\n",
    "    space['n_estimators'] = [25, 50]\n",
    "    \n",
    "    ada_search = GridSearchCV(ada, space, scoring='roc_auc', cv=cv_inner, refit=True)\n",
    "    result = ada_search.fit(data_train, target_train)\n",
    "    \n",
    "    best_model = result.best_estimator_\n",
    "    yhat = best_model.predict(data_test)\n",
    "    performance[8][0] += metrics.accuracy_score(target_test, yhat)\n",
    "    performance[8][1] += metrics.f1_score(target_test, yhat)\n",
    "    performance[8][2] += metrics.roc_auc_score(target_test, yhat)\n",
    "    \n",
    "    print(\"Ada Boost Best Param:\", result.best_params_)\n",
    "    \n",
    "    split += 1\n",
    "    print()\n",
    "# Average of Performance Measures\n",
    "for i in range(9):\n",
    "    for n in range(3):\n",
    "        performance[i][n] = performance[i][n] / 10\n",
    "        \n",
    "performance = pd.DataFrame(performance, columns = cols, index = rows)\n",
    "display(performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
